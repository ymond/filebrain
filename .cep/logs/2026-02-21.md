## Session: First Session

### Summary
Bootstrapped the entire filebrain project from scratch. Created the Python package
structure with pyproject.toml and src layout, set up a virtual environment with
pytest, verified ollama was installed and pulled the nomic-embed-text embedding
model (already present) and qwen2.5:7b chat model (new). Designed and implemented
the complete extractor subsystem via strict TDD: the base Extractor ABC and
ExtractionResult dataclass, PlainTextExtractor (with encoding detection and binary
file rejection), PdfExtractor (using pymupdf), CodeExtractor (with language detection
for 40+ extensions), and ExtractorRegistry (maps file extensions to extractors with
custom extractor support). All 48 tests pass.

### Decisions Made
- **Decision:** Use `hatchling` as the build backend
  - **Alternatives considered:** setuptools, flit, poetry
  - **Why this choice:** Modern, fast, good src-layout support, minimal config
  - **Reversibility:** Easy — just change pyproject.toml build-system

- **Decision:** Qwen 2.5 7B as the local chat model (ADR-001)
  - **Alternatives considered:** Llama 3.1 8B, Gemma 2 9B, Mistral 7B
  - **Why this choice:** Best instruction following at 7B scale, fits in 8GB VRAM
    alongside embedding model (~4.7GB + 274MB = ~5GB of 8GB)
  - **Reversibility:** Easy — just pull a different model and change config

- **Decision:** Binary file detection via null byte check (`\x00 in raw`)
  - **Alternatives considered:** Trying to decode and catching errors, magic byte detection
  - **Why this choice:** latin-1 can decode any byte sequence, so decode-based
    detection doesn't work. Null bytes are the simplest reliable indicator of
    binary content. Standard approach used by git and many other tools.
  - **Reversibility:** Easy

- **Decision:** Use `str.splitlines()` for line counting instead of `count("\n") + 1`
  - **Alternatives considered:** `count("\n") + 1`
  - **Why this choice:** `splitlines()` correctly handles trailing newlines (a file
    with "line1\nline2\n" has 2 lines, not 3)
  - **Reversibility:** Easy

### Mikado Tree Progress
- Active path: goal > storage_layer > sqlite_metadata > design_schema (next session)
- [x] Project setup and infrastructure (MHC 9) — all 3 children done
  - [x] Scaffold Python package (MHC 8)
  - [x] Set up ollama models (MHC 8) — ADR-001 written
  - [x] Smoke test (MHC 8)
- [x] Extractor interface and core extractors (MHC 10) — all children done
  - [x] Design Extractor interface via TDD (MHC 10) — 9 tests
  - [x] PlainTextExtractor (MHC 9) — 12 tests
  - [x] PdfExtractor (MHC 9) — 8 tests
  - [x] CodeExtractor (MHC 9) — 9 tests
  - [x] ExtractorRegistry (MHC 10) — 8 tests + custom extractor test
- New nodes discovered: None — the Mikado tree was well-decomposed

### TDD Cycle Log
1. **Extractor interface:** Wrote 9 tests defining the contract (ExtractionResult
   with text+metadata, Extractor ABC with supported_extensions/mime_types/extract,
   ExtractionError). All failed (ModuleNotFoundError). Implemented `base.py` with
   ABC, dataclass, and exception. All 9 passed. No refactoring needed.

2. **PlainTextExtractor:** Wrote 12 tests covering .txt/.md/.log/.csv extraction,
   encoding detection (UTF-8, Latin-1), metadata (size, line count), error cases
   (missing file, binary file). All failed. Implemented `plain_text.py`. 11 passed,
   1 failed: binary detection test. Root cause: latin-1 decodes any byte sequence.
   Fixed test to use null bytes as binary indicator, added `\x00` check. 12 passed.

3. **PdfExtractor:** Wrote 8 tests using pymupdf to create test PDFs in the test
   helper. Single page, multi-page, page count metadata, error cases. Implemented
   `pdf.py`. All 8 passed first try.

4. **CodeExtractor:** Wrote 9 tests for .py/.js/.sh extraction, language detection,
   line count, error handling. Implemented `code.py`. 8 passed, 1 failed: line count
   off-by-one with trailing newline. Fixed using `splitlines()`. Applied same fix
   to PlainTextExtractor for consistency. All 9 passed.

5. **ExtractorRegistry:** Wrote 8 tests: correct extractor for each type, None for
   unknown, custom extractor registration. Implemented `registry.py`. All 8 passed.

### What I Learned (for Raymond)
**The latin-1 encoding trap:** When building text file detection, a naive approach
of "try to decode it — if it fails, it's binary" doesn't work because ISO 8859-1
(latin-1) can decode literally any byte sequence (it maps every byte 0x00-0xFF to
a character). This is why tools like `git` use null byte detection: if a file
contains `\x00`, it's almost certainly binary. Real text files essentially never
contain null bytes.

**Python's `str.splitlines()` vs `count("\n") + 1`:** The `count + 1` approach
gives the wrong answer for files ending in newlines (which is most files — POSIX
convention). `"line1\nline2\n".count("\n") + 1` gives 3, but there are only 2 lines.
`splitlines()` returns `["line1", "line2"]` — correct. Always use `splitlines()`.

**pymupdf renamed to `pymupdf`:** The import is now `import pymupdf` (not the old
`import fitz`). The package name on PyPI changed too. The old `fitz` import still
works as an alias but the canonical way is `pymupdf`.

### Open Questions
None — next session should proceed to the Storage layer (SQLite metadata store).
The next active node will be designing the schema.
